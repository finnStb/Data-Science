{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Classification Exercise (40 points + 3 point extra) ✔\n",
    "There are 2 files: training and test.\n",
    "\n",
    "This dataset is designed to understand the factors that lead a person to leave their current job for HR research. By using model(s) that leverage current credentials, demographics, and experience data, you will predict the probability of a candidate looking for a new job or continuing to work for the company, as well as interpreting affected factors on employee decision.\n",
    "\n",
    "### Note:\n",
    "- The dataset is imbalanced.\n",
    "- Most features are categorical (Nominal, Ordinal, Binary), some with high cardinality.\n",
    "- Missing imputation can be a part of your pipeline as well.\n",
    "\n",
    "### Features\n",
    "\n",
    "| Feature                   | Description                                            |\n",
    "|---------------------------|--------------------------------------------------------|\n",
    "| city_development_index    | Development index of the city (scaled)                 |\n",
    "| gender                    | Gender of candidate                                    |\n",
    "| relevent_experience       | Relevant experience of candidate                      |\n",
    "| enrolled_university       | Type of University course enrolled if any             |\n",
    "| education_level           | Education level of candidate                          |\n",
    "| major_discipline          | Education major discipline of candidate               |\n",
    "| experience                | Candidate's total experience in years                 |\n",
    "| company_type              | Type of current employer                              |\n",
    "| last_new_job              | Difference in years between previous job and current job |\n",
    "| training_hours            | Training hours completed                              |\n",
    "| target                    | 0 – Not looking for job change, 1 – Looking for a job change |\n",
    "\n",
    "## Task 1: Data Cleaning and Imputation\n",
    "\n",
    "1. In `experience`, replace `>20` with `21`; `<1` with `1`, and convert this column to numerical.\n",
    "2. In `last_new_job`, replace `>4` with `5`; `never` with `0`, and convert this column to numerical.\n",
    "3. If the column is categorical, impute the missing values with its mode. If the column is numerical, impute the missing values with its median."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29256d0832e7c305"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.464251500Z",
     "start_time": "2024-07-18T22:27:45.364405600Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('data/aug_train.csv')\n",
    "df_test = pd.read_csv('data/aug_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "   city_development_index  gender      relevent_experience  \\\n0                   0.624    Male   No relevent experience   \n1                   0.926    Male  Has relevent experience   \n2                   0.920    Male  Has relevent experience   \n3                   0.624    Male   No relevent experience   \n4                   0.920  Female  Has relevent experience   \n\n  enrolled_university education_level major_discipline experience  \\\n0       no_enrollment     High School              NaN          5   \n1       no_enrollment        Graduate             STEM        >20   \n2       no_enrollment        Graduate             STEM        >20   \n3    Full time course     High School              NaN          1   \n4       no_enrollment         Masters             STEM        >20   \n\n    company_type last_new_job  training_hours  target  \n0            NaN        never              21       0  \n1            NaN           >4              12       0  \n2  Public Sector           >4              26       0  \n3            NaN        never              30       1  \n4            NaN           >4              46       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city_development_index</th>\n      <th>gender</th>\n      <th>relevent_experience</th>\n      <th>enrolled_university</th>\n      <th>education_level</th>\n      <th>major_discipline</th>\n      <th>experience</th>\n      <th>company_type</th>\n      <th>last_new_job</th>\n      <th>training_hours</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.624</td>\n      <td>Male</td>\n      <td>No relevent experience</td>\n      <td>no_enrollment</td>\n      <td>High School</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>never</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.926</td>\n      <td>Male</td>\n      <td>Has relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Graduate</td>\n      <td>STEM</td>\n      <td>&gt;20</td>\n      <td>NaN</td>\n      <td>&gt;4</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.920</td>\n      <td>Male</td>\n      <td>Has relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Graduate</td>\n      <td>STEM</td>\n      <td>&gt;20</td>\n      <td>Public Sector</td>\n      <td>&gt;4</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.624</td>\n      <td>Male</td>\n      <td>No relevent experience</td>\n      <td>Full time course</td>\n      <td>High School</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>never</td>\n      <td>30</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.920</td>\n      <td>Female</td>\n      <td>Has relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Masters</td>\n      <td>STEM</td>\n      <td>&gt;20</td>\n      <td>NaN</td>\n      <td>&gt;4</td>\n      <td>46</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.754002300Z",
     "start_time": "2024-07-18T22:27:45.377399400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city_development_index  2100 non-null   float64\n",
      " 1   gender                  1585 non-null   object \n",
      " 2   relevent_experience     2100 non-null   object \n",
      " 3   enrolled_university     2051 non-null   object \n",
      " 4   education_level         2049 non-null   object \n",
      " 5   major_discipline        1768 non-null   object \n",
      " 6   experience              2090 non-null   object \n",
      " 7   company_type            1415 non-null   object \n",
      " 8   last_new_job            2048 non-null   object \n",
      " 9   training_hours          2100 non-null   int64  \n",
      " 10  target                  2100 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 180.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the data\n",
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.755554400Z",
     "start_time": "2024-07-18T22:27:45.390570700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "       city_development_index  training_hours       target\ncount             2100.000000     2100.000000  2100.000000\nmean                 0.826898       65.896190     0.254762\nstd                  0.124464       58.432483     0.435831\nmin                  0.448000        1.000000     0.000000\n25%                  0.729250       24.000000     0.000000\n50%                  0.899000       49.000000     0.000000\n75%                  0.920000       89.250000     1.000000\nmax                  0.949000      336.000000     1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city_development_index</th>\n      <th>training_hours</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2100.000000</td>\n      <td>2100.000000</td>\n      <td>2100.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.826898</td>\n      <td>65.896190</td>\n      <td>0.254762</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.124464</td>\n      <td>58.432483</td>\n      <td>0.435831</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.448000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.729250</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.899000</td>\n      <td>49.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.920000</td>\n      <td>89.250000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.949000</td>\n      <td>336.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.757689500Z",
     "start_time": "2024-07-18T22:27:45.405345600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "city_development_index     79\ngender                      3\nrelevent_experience         2\nenrolled_university         3\neducation_level             5\nmajor_discipline            6\nexperience                 22\ncompany_type                6\nlast_new_job                6\ntraining_hours            220\ntarget                      2\ndtype: int64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values for each column\n",
    "df_train.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.758687600Z",
     "start_time": "2024-07-18T22:27:45.421903900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "city_development_index      0\ngender                    515\nrelevent_experience         0\nenrolled_university        49\neducation_level            51\nmajor_discipline          332\nexperience                 10\ncompany_type              685\nlast_new_job               52\ntraining_hours              0\ntarget                      0\ndtype: int64"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values for each column\n",
    "df_train.isnull().sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.842561300Z",
     "start_time": "2024-07-18T22:27:45.429458200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "experience\n>20    369\n5      170\n2      145\n3      134\n6      130\n4      124\n7      123\n9      109\n10     103\n8       86\n11      79\n1       73\n15      72\n12      68\n14      55\n16      49\n<1      46\n13      41\n17      40\n18      30\n19      28\n20      16\nName: count, dtype: int64"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['experience'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.845312400Z",
     "start_time": "2024-07-18T22:27:45.439146300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. In `experience`, replace `>20` with `21`; `<1` with `1`, and convert this column to numerical."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience\n",
      "21.0    369\n",
      "5.0     170\n",
      "2.0     145\n",
      "3.0     134\n",
      "6.0     130\n",
      "4.0     124\n",
      "7.0     123\n",
      "1.0     119\n",
      "9.0     109\n",
      "10.0    103\n",
      "8.0      86\n",
      "11.0     79\n",
      "15.0     72\n",
      "12.0     68\n",
      "14.0     55\n",
      "16.0     49\n",
      "13.0     41\n",
      "17.0     40\n",
      "18.0     30\n",
      "19.0     28\n",
      "20.0     16\n",
      "Name: count, dtype: int64\n",
      "experience\n",
      "21.0    17\n",
      "10.0    10\n",
      "4.0      9\n",
      "7.0      7\n",
      "15.0     7\n",
      "3.0      6\n",
      "2.0      6\n",
      "5.0      6\n",
      "1.0      5\n",
      "8.0      5\n",
      "6.0      4\n",
      "11.0     3\n",
      "12.0     3\n",
      "18.0     3\n",
      "14.0     2\n",
      "16.0     2\n",
      "9.0      2\n",
      "13.0     2\n",
      "20.0     1\n",
      "Name: count, dtype: int64\n",
      "NaN values: 10\n"
     ]
    }
   ],
   "source": [
    "df_train['experience'] = df_train['experience'].replace({'>20': '21', '<1': '1'}).astype(float)\n",
    "df_test['experience'] = df_test['experience'].replace({'>20': '21', '<1': '1'}).astype(float)\n",
    "\n",
    "# check\n",
    "print(df_train['experience'].value_counts())\n",
    "print(df_test['experience'].value_counts())\n",
    "print(\"NaN values:\", df_train['experience'].isnull().sum() + df_test['experience'].isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.846459500Z",
     "start_time": "2024-07-18T22:27:45.450599500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. In `last_new_job`, replace `>4` with `5`; `never` with `0`, and convert this column to numerical."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_new_job\n",
      "1.0    857\n",
      "5.0    357\n",
      "2.0    322\n",
      "0.0    284\n",
      "3.0    115\n",
      "4.0    113\n",
      "Name: count, dtype: int64\n",
      "last_new_job\n",
      "1.0    40\n",
      "5.0    23\n",
      "2.0    19\n",
      "0.0    12\n",
      "4.0     5\n",
      "3.0     1\n",
      "Name: count, dtype: int64\n",
      "NaN values: 52\n"
     ]
    }
   ],
   "source": [
    "df_train['last_new_job'] = df_train['last_new_job'].replace({'>4': '5', 'never': '0'}).astype(float)\n",
    "df_test['last_new_job'] = df_test['last_new_job'].replace({'>4': '5', 'never': '0'}).astype(float)\n",
    "\n",
    "# check\n",
    "print(df_train['last_new_job'].value_counts())\n",
    "print(df_test['last_new_job'].value_counts())\n",
    "print(\"NaN values:\", df_train['last_new_job'].isnull().sum() + df_test['last_new_job'].isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.846569600Z",
     "start_time": "2024-07-18T22:27:45.464251500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. If the column is categorical, impute the missing values with its mode. If the column is numerical, impute the missing values with its median.\n",
    "# note: imputing with mode or median can alter the data heavily, but i will do it for this exercise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_development_index    0\n",
      "gender                    0\n",
      "relevent_experience       0\n",
      "enrolled_university       0\n",
      "education_level           0\n",
      "major_discipline          0\n",
      "experience                0\n",
      "company_type              0\n",
      "last_new_job              0\n",
      "training_hours            0\n",
      "target                    0\n",
      "dtype: int64\n",
      "city_development_index    0\n",
      "gender                    0\n",
      "relevent_experience       0\n",
      "enrolled_university       0\n",
      "education_level           0\n",
      "major_discipline          0\n",
      "experience                0\n",
      "company_type              0\n",
      "last_new_job              0\n",
      "training_hours            0\n",
      "target                    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city_development_index  2100 non-null   float64\n",
      " 1   gender                  2100 non-null   object \n",
      " 2   relevent_experience     2100 non-null   object \n",
      " 3   enrolled_university     2100 non-null   object \n",
      " 4   education_level         2100 non-null   object \n",
      " 5   major_discipline        2100 non-null   object \n",
      " 6   experience              2100 non-null   float64\n",
      " 7   company_type            2100 non-null   object \n",
      " 8   last_new_job            2100 non-null   float64\n",
      " 9   training_hours          2100 non-null   int64  \n",
      " 10  target                  2100 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 180.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        mode_value_train = df_train[col].mode()[0]\n",
    "        mode_value_test = df_test[col].mode()[0]\n",
    "        df_train[col] = df_train[col].fillna(mode_value_train)\n",
    "        df_test[col] = df_test[col].fillna(mode_value_test)\n",
    "    else:\n",
    "        median_value_train = df_train[col].median()\n",
    "        median_value_test = df_test[col].median()\n",
    "        df_train[col] = df_train[col].fillna(median_value_train)\n",
    "        df_test[col] = df_test[col].fillna(median_value_test)\n",
    "\n",
    "# check\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "\n",
    "# check data types again\n",
    "df_train.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.893796800Z",
     "start_time": "2024-07-18T22:27:45.477460900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: Classification\n",
    "\n",
    "1. Build a classification model from the training set (you can use any algorithms).\n",
    "## i will use Random Forest, because it has good performance for non-linear classification problems.\n",
    "2. Generate the confusion matrix and calculate the accuracy, precision, recall, and F1-score on the training set.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9990476190476191\n",
      "\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1565\n",
      "           1       1.00      1.00      1.00       535\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[1565    0]\n",
      " [   2  533]]\n"
     ]
    }
   ],
   "source": [
    "# use df_train for training and df_test for testing. so no need to split the data.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# convert categorical to numerical. we have to concat the two dataframes first to avoid mismatch in columns after get_dummies().\n",
    "# concatenate df_train and df_test\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "\n",
    "# apply get_dummies on the combined dataframe\n",
    "df_combined = pd.get_dummies(df_combined, drop_first=True)\n",
    "\n",
    "# split back into train and test\n",
    "df_train = df_combined[:df_train.shape[0]]\n",
    "df_test = df_combined[df_train.shape[0]:]\n",
    "\n",
    "# separate features and target\n",
    "X_train = df_train.drop('target', axis=1)\n",
    "y_train = df_train['target']\n",
    "\n",
    "# train model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict on training set\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "# evaluate on training set\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"\\nTraining Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "print(\"\\nTraining Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.976391100Z",
     "start_time": "2024-07-18T22:27:45.498685200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Apply the model to the test set and generate the predictions.\n",
    "4. Generate the confusion matrix from the test set and calculate the accuracy, precision, recall, and F1-score.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.82\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        78\n",
      "           1       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.75      0.66      0.68       100\n",
      "weighted avg       0.80      0.82      0.80       100\n",
      "\n",
      "\n",
      "Test Confusion Matrix:\n",
      " [[74  4]\n",
      " [14  8]]\n"
     ]
    }
   ],
   "source": [
    "# seperate features and target\n",
    "X_test = df_test.drop('target', axis=1)\n",
    "y_test = df_test['target']\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# evaluate on test set\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nTest Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.977409Z",
     "start_time": "2024-07-18T22:27:45.808294500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 16 Important Features according to Random Forest:\n",
      "training_hours                                0.289\n",
      "city_development_index                        0.256\n",
      "experience                                    0.169\n",
      "last_new_job                                  0.080\n",
      "enrolled_university_no_enrollment             0.028\n",
      "relevent_experience_No relevent experience    0.026\n",
      "education_level_Masters                       0.023\n",
      "education_level_High School                   0.019\n",
      "gender_Male                                   0.016\n",
      "company_type_Pvt Ltd                          0.016\n",
      "enrolled_university_Part time course          0.012\n",
      "major_discipline_STEM                         0.011\n",
      "company_type_Public Sector                    0.010\n",
      "major_discipline_Humanities                   0.007\n",
      "company_type_Funded Startup                   0.007\n",
      "education_level_Primary School                0.005\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# feature importance (extra)\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# also print the top 16 features\n",
    "print(\"Top 16 Important Features according to Random Forest:\")\n",
    "# print rounded to 4 decimal places\n",
    "print(np.round(feat_importances.nlargest(16), 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.977409Z",
     "start_time": "2024-07-18T22:27:45.833218700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Compare the results between the training and test sets.\n",
    "\n",
    "These results are expected because the model is trained on the training data (of course it will perform well on it), but when applied to the test data, the performance drops significantly. It still performs okay though.\n",
    "I will focus on the test results now, because that is the real evaluation of the model:\n",
    "Test Accuracy: 0.81\n",
    "\n",
    "## Test Classification Report\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 0.83      | 0.95   | 0.89     | 78      |\n",
    "| 1     | 0.64      | 0.32   | 0.42     | 22      |\n",
    "|       |           |        |          |         |\n",
    "| **Accuracy**            |           |        | 0.81     | 100     |\n",
    "| **Macro Avg** | 0.73      | 0.63   | 0.66     | 100     |\n",
    "| **Weighted Avg** | 0.79      | 0.81   | 0.78     | 100     |\n",
    "\n",
    "\n",
    "\n",
    "Test Confusion Matrix:\n",
    " [[74  4]\n",
    " [15  7]]\n",
    "Overall accuracy is 0.81, which means the target (looking for a job change or not) is predicted correctly 81% of the time.\n",
    "The precision for class 0 (not looking for job change) is 0.83 while the precision for class 1 (looking for job change) is only 0.64, which means the model is better at predicting class 0 than class 1. But WHY? BECAUSE THE DATA IS IMBALANCED! There are more samples for class 0 than class 1, so the model is biased towards predicting class 0. This is a common issue in imbalanced datasets. Recall and F1-score also show similar trends, as well as the confusion matrix.\n",
    "Also, imputing missing values with mode or median can affect the performance of the model, especially with a lot of missing values, like in this case.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extra Point:\n",
    "Think about what kind of methods can increase performance (does not need to be run).\n",
    "\n",
    "## 1. Remove the imbalance of the dataset by oversampling the minority class or undersampling the majority class.\n",
    "## 2. Use better imputation techniques for missing values, like KNN imputation or MICE.\n",
    "## 3. Try different algorithms and tune hyperparameters for better performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender values in dataset:  ['Male' 'Female' nan 'Other']\n",
      "count num of each gender value: \n",
      " gender\n",
      "Male      1422\n",
      "NaN        515\n",
      "Female     133\n",
      "Other       30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# just for demonstration, i will show some missing data and what they are (WRONGLY) imputed to.\n",
    "# lets take gender for example\n",
    "\n",
    "# reload the data from the original csv files\n",
    "df_train = pd.read_csv('data/aug_train.csv')\n",
    "df_test = pd.read_csv('data/aug_test.csv')\n",
    "\n",
    "# distinct gender values in dataset (Annahme: im Testdatensatz sind die gleichen):\n",
    "print(\"gender values in dataset: \", df_train['gender'].unique())\n",
    "\n",
    "# print how many of each gender value there are in the training set\n",
    "print(\"count num of each gender value: \\n\", df_train['gender'].value_counts(dropna=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.978418600Z",
     "start_time": "2024-07-18T22:27:45.847574900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So what we see is 1422 rows with Male, only 133 with Female, 30 with Other BUT 515 ROWS WITH NaN (missing values).\n",
    "If we just impute these missing values (which may be purposefully not provided by the candidates), we are just assuming they are all Male.\n",
    "What i would do instead is to create a new category for these missing values, like \"Not Provided\" or \"Unknown\", which can also add some information to the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# impute missing categorical values with a new category \"Not Provided\" and numerical values with -999\n",
    "for col in df_train.select_dtypes(include=['object']).columns:\n",
    "    df_train[col] = df_train[col].fillna('Not Provided')\n",
    "    df_test[col] = df_test[col].fillna('Not Provided')\n",
    "\n",
    "for col in df_train.select_dtypes(include=['number']).columns:\n",
    "    df_train[col] = df_train[col].fillna(-999)\n",
    "    df_test[col] = df_test[col].fillna(-999)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:45.979424Z",
     "start_time": "2024-07-18T22:27:45.863040300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target after SMOTE:\n",
      " target\n",
      "0    1565\n",
      "1    1565\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# separate features and target\n",
    "X_train = df_train.drop('target', axis=1)\n",
    "y_train = df_train['target']\n",
    "\n",
    "# apply SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# check new distribution of target variable\n",
    "print(\"Distribution of target after SMOTE:\\n\", y_train_res.value_counts())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T22:27:46.570795400Z",
     "start_time": "2024-07-18T22:27:46.231106300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
